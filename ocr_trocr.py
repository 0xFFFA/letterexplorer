#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCR —Å–∫—Ä–∏–ø—Ç –Ω–∞ –±–∞–∑–µ TrOCR —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–µ—á–∞—Ç–Ω–æ–≥–æ –∏ —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ç–µ–∫—Å—Ç–∞ –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å
"""

import argparse
import os
import sys
from pathlib import Path
import cv2
import numpy as np
from PIL import Image
import fitz  # PyMuPDF –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PDF
from typing import List, Tuple, Dict
import warnings
warnings.filterwarnings('ignore')

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫
try:
    from transformers import TrOCRProcessor as HFTrOCRProcessor, VisionEncoderDecoderModel
    import torch
    TROCR_AVAILABLE = True
except ImportError:
    TROCR_AVAILABLE = False
    print("‚ùå –û—à–∏–±–∫–∞: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ transformers –∏ torch")
    print("   pip install transformers torch pillow")
    sys.exit(1)


class TextTypeDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä —Ç–∏–ø–∞ —Ç–µ–∫—Å—Ç–∞: –ø–µ—á–∞—Ç–Ω—ã–π vs —Ä—É–∫–æ–ø–∏—Å–Ω—ã–π"""
    
    @staticmethod
    def analyze_text_region(image_region):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±–ª–∞—Å—Ç—å –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ç–µ–∫—Å—Ç–∞"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
        if len(image_region.shape) == 3:
            gray = cv2.cvtColor(image_region, cv2.COLOR_BGR2GRAY)
        else:
            gray = image_region.copy()
        
        # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ç–µ–∫—Å—Ç–∞
        
        # 1. –í–∞—Ä–∏–∞—Ü–∏—è —Ç–æ–ª—â–∏–Ω—ã —à—Ç—Ä–∏—Ö–æ–≤ (—Ä—É–∫–æ–ø–∏—Å–Ω—ã–π —Ç–µ–∫—Å—Ç –±–æ–ª–µ–µ –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π)
        edges = cv2.Canny(binary, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # 2. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç—É—Ä–æ–≤ (—Ä—É–∫–æ–ø–∏—Å–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–º–µ–µ—Ç –±–æ–ª—å—à–µ –º–µ–ª–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π)
        contours, _ = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        contour_count = len(contours)
        
        # 3. –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —á–µ—Ä–Ω—ã—Ö –∏ –±–µ–ª—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π
        black_ratio = np.sum(binary > 0) / binary.size
        
        # 4. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ (—Ä—É–∫–æ–ø–∏—Å–Ω—ã–π –±–æ–ª–µ–µ –≤–∞—Ä–∏–∞—Ç–∏–≤–µ–Ω)
        std_dev = np.std(gray)
        
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        handwritten_score = 0
        
        if edge_density > 0.1:  # –ú–Ω–æ–≥–æ –∫—Ä–∞–µ–≤
            handwritten_score += 1
        if contour_count > 50:  # –ú–Ω–æ–≥–æ –º–µ–ª–∫–∏—Ö –∫–æ–Ω—Ç—É—Ä–æ–≤
            handwritten_score += 1
        if black_ratio < 0.15:  # –¢–æ–Ω–∫–∏–µ —à—Ç—Ä–∏—Ö–∏
            handwritten_score += 1
        if std_dev > 40:  # –í—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
            handwritten_score += 1
        
        is_handwritten = handwritten_score >= 2
        
        return {
            'is_handwritten': is_handwritten,
            'confidence': handwritten_score / 4.0,
            'edge_density': edge_density,
            'contour_count': contour_count,
            'std_dev': std_dev
        }


class TableDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä —Ç–∞–±–ª–∏—Ü –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
    
    @staticmethod
    def detect_tables(image):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–±–ª–∞—Å—Ç–∏ —Ç–∞–±–ª–∏—Ü"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
        _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)
        
        # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –∏ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        
        horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)
        vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel, iterations=2)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ª–∏–Ω–∏–∏
        table_mask = cv2.add(horizontal_lines, vertical_lines)
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã)
        contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        table_regions = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏
            if w > 200 and h > 100:
                table_regions.append((x, y, w, h))
        
        return table_regions
    
    @staticmethod
    def remove_table_lines(image_region):
        """–£–¥–∞–ª—è–µ—Ç –ª–∏–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ª—É—á—à–µ–≥–æ OCR"""
        gray = cv2.cvtColor(image_region, cv2.COLOR_BGR2GRAY) if len(image_region.shape) == 3 else image_region
        
        # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
        _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)
        
        # –£–¥–∞–ª—è–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        remove_horizontal = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)
        
        # –£–¥–∞–ª—è–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        remove_vertical = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel, iterations=2)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏–Ω–∏–∏ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        result = binary.copy()
        result = cv2.subtract(result, remove_horizontal)
        result = cv2.subtract(result, remove_vertical)
        
        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ
        result = cv2.bitwise_not(result)
        
        return result


class TrOCRProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞ –±–∞–∑–µ TrOCR"""
    
    def __init__(self, use_gpu=True):
        self.use_gpu = use_gpu and torch.cuda.is_available()
        self.device = "cuda" if self.use_gpu else "cpu"
        
        print(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device.upper()}")
        
        # –ú–æ–¥–µ–ª–∏
        self.printed_processor = None
        self.printed_model = None
        self.handwritten_processor = None
        self.handwritten_model = None
        
        self.text_detector = TextTypeDetector()
        self.table_detector = TableDetector()
    
    def initialize_printed_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–µ—á–∞—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        if self.printed_processor is None:
            print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–µ—á–∞—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞...")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å TrOCR –¥–ª—è –ø–µ—á–∞—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            self.printed_processor = HFTrOCRProcessor.from_pretrained('microsoft/trocr-base-printed')
            self.printed_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')
            self.printed_model.to(self.device)
            self.printed_model.eval()
            print("‚úÖ –ú–æ–¥–µ–ª—å –¥–ª—è –ø–µ—á–∞—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return self.printed_processor, self.printed_model
    
    def initialize_handwritten_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        if self.handwritten_processor is None:
            print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞...")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            self.handwritten_processor = HFTrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
            self.handwritten_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')
            self.handwritten_model.to(self.device)
            self.handwritten_model.eval()
            print("‚úÖ –ú–æ–¥–µ–ª—å –¥–ª—è —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return self.handwritten_processor, self.handwritten_model
    
    def preprocess_image(self, image, enhance=True):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        if enhance:
            # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(gray)
            
            # –£–±–∏—Ä–∞–µ–º —à—É–º
            denoised = cv2.fastNlMeansDenoising(enhanced, None, 10, 7, 21)
            
            return denoised
        
        return gray
    
    def segment_text_lines(self, image):
        """–°–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # –ü—Ä–æ–µ–∫—Ü–∏—è –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç—Ä–æ–∫
        horizontal_projection = np.sum(binary, axis=1)
        
        # –ù–∞—Ö–æ–¥–∏–º –≥—Ä–∞–Ω–∏—Ü—ã —Å—Ç—Ä–æ–∫
        threshold = np.max(horizontal_projection) * 0.1
        in_text = False
        lines = []
        start_y = 0
        
        for i, value in enumerate(horizontal_projection):
            if not in_text and value > threshold:
                in_text = True
                start_y = i
            elif in_text and value < threshold:
                in_text = False
                if i - start_y > 10:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤—ã—Å–æ—Ç–∞ —Å—Ç—Ä–æ–∫–∏
                    lines.append((start_y, i))
        
        return lines
    
    def recognize_line(self, image, line_coords, is_handwritten=False):
        """–†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Ç–µ–∫—Å—Ç–∞"""
        y_start, y_end = line_coords
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø—ã
        y_start = max(0, y_start - 5)
        y_end = min(image.shape[0], y_end + 5)
        
        line_img = image[y_start:y_end, :]
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL Image
        if len(line_img.shape) == 2:
            pil_img = Image.fromarray(line_img).convert('RGB')
        else:
            pil_img = Image.fromarray(cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB))
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å
        if is_handwritten:
            processor, model = self.initialize_handwritten_model()
        else:
            processor, model = self.initialize_printed_model()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞
        pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values
        pixel_values = pixel_values.to(self.device)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
        with torch.no_grad():
            generated_ids = model.generate(pixel_values)
        
        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        
        return generated_text
    
    def process_image(self, image_path, detect_tables=True, auto_detect_handwritten=True):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ç–∏–ø–∞ —Ç–µ–∫—Å—Ç–∞"""
        print(f"\nüìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {image_path}")
        
        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        
        all_text = []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—ã
        table_regions = []
        if detect_tables:
            table_regions = self.table_detector.detect_tables(image)
            if table_regions:
                print(f"  üìä –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(table_regions)}")
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –æ–±–ª–∞—Å—Ç–µ–π –≤–Ω–µ —Ç–∞–±–ª–∏—Ü
        mask = np.ones(image.shape[:2], dtype=np.uint8) * 255
        for x, y, w, h in table_regions:
            mask[y:y+h, x:x+w] = 0
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç (–≤–Ω–µ —Ç–∞–±–ª–∏—Ü)
        text_image = cv2.bitwise_and(image, image, mask=mask)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        preprocessed = self.preprocess_image(text_image, enhance=True)
        
        # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ —Å—Ç—Ä–æ–∫–∏
        lines = self.segment_text_lines(preprocessed)
        print(f"  üìù –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Ç–µ–∫—Å—Ç–∞: {len(lines)}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É
        for idx, line_coords in enumerate(lines):
            y_start, y_end = line_coords
            line_region = preprocessed[y_start:y_end, :]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç–µ–∫—Å—Ç–∞
            if auto_detect_handwritten and line_region.shape[0] > 10 and line_region.shape[1] > 10:
                text_info = self.text_detector.analyze_text_region(line_region)
                is_handwritten = text_info['is_handwritten']
                
                if is_handwritten:
                    print(f"    ‚úçÔ∏è  –°—Ç—Ä–æ–∫–∞ {idx+1}: —Ä—É–∫–æ–ø–∏—Å–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {text_info['confidence']:.2f})")
            else:
                is_handwritten = False
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Å—Ç—Ä–æ–∫—É
            try:
                text = self.recognize_line(preprocessed, line_coords, is_handwritten=is_handwritten)
                if text.strip():
                    all_text.append(text.strip())
            except Exception as e:
                print(f"    ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Å—Ç—Ä–æ–∫–∏ {idx+1}: {e}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
        for idx, (x, y, w, h) in enumerate(table_regions):
            print(f"  üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü—ã {idx+1}...")
            table_img = image[y:y+h, x:x+w]
            
            # –£–¥–∞–ª—è–µ–º –ª–∏–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü—ã
            table_no_lines = self.table_detector.remove_table_lines(table_img)
            
            # –°–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—É –Ω–∞ —Å—Ç—Ä–æ–∫–∏
            table_lines = self.segment_text_lines(table_no_lines)
            
            table_text = ["\n=== –¢–ê–ë–õ–ò–¶–ê ==="]
            for line_coords in table_lines:
                try:
                    text = self.recognize_line(table_no_lines, line_coords, is_handwritten=False)
                    if text.strip():
                        table_text.append(text.strip())
                except Exception as e:
                    pass
            
            table_text.append("=== –ö–û–ù–ï–¶ –¢–ê–ë–õ–ò–¶–´ ===\n")
            all_text.extend(table_text)
        
        return '\n'.join(all_text)
    
    def convert_pdf_to_images(self, pdf_path, resolution=5.0):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        doc = fitz.open(pdf_path)
        images = []
        
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            mat = fitz.Matrix(resolution, resolution)
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            
            nparr = np.frombuffer(img_data, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            images.append(img)
        
        doc.close()
        return images


def main():
    parser = argparse.ArgumentParser(description='OCR —Å TrOCR –¥–ª—è –ø–µ—á–∞—Ç–Ω–æ–≥–æ –∏ —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞')
    parser.add_argument('--input', '-i', 
                       default='input',
                       help='–ö–∞—Ç–∞–ª–æ–≥ —Å –≤—Ö–æ–¥–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏')
    parser.add_argument('--output', '-o',
                       default='output_trocr', 
                       help='–ö–∞—Ç–∞–ª–æ–≥ –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤')
    parser.add_argument('--no-gpu', action='store_true',
                       help='–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU')
    parser.add_argument('--no-tables', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü')
    parser.add_argument('--no-handwritten', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞')
    parser.add_argument('--resolution', type=float, default=5.0,
                       help='–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è PDF (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5.0)')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥–∏
    input_dir = Path(args.input)
    output_dir = Path(args.output)
    output_dir.mkdir(exist_ok=True)
    
    if not input_dir.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –ö–∞—Ç–∞–ª–æ–≥ {input_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        sys.exit(1)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = TrOCRProcessor(use_gpu=not args.no_gpu)
    
    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
    pdf_extensions = {'.pdf'}
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
    processed_files = 0
    
    for file_path in sorted(input_dir.iterdir()):
        if file_path.is_file():
            file_ext = file_path.suffix.lower()
            
            if file_ext in image_extensions:
                try:
                    text = processor.process_image(
                        str(file_path),
                        detect_tables=not args.no_tables,
                        auto_detect_handwritten=not args.no_handwritten
                    )
                    
                    output_file = output_dir / f"{file_path.stem}.txt"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(text)
                    
                    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
                    processed_files += 1
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}")
                
            elif file_ext in pdf_extensions:
                try:
                    print(f"\nüìë –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF: {file_path}")
                    images = processor.convert_pdf_to_images(str(file_path), resolution=args.resolution)
                    
                    all_text = []
                    for i, image in enumerate(images):
                        print(f"\nüìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i+1}/{len(images)}")
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                        temp_path = f"/tmp/temp_trocr_page_{i}.png"
                        cv2.imwrite(temp_path, image)
                        
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                        text = processor.process_image(
                            temp_path,
                            detect_tables=not args.no_tables,
                            auto_detect_handwritten=not args.no_handwritten
                        )
                        
                        if text.strip():
                            all_text.append(f"--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i+1} ---\n{text}\n")
                        
                        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                        os.remove(temp_path)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    output_file = output_dir / f"{file_path.stem}.txt"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write('\n'.join(all_text))
                    
                    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
                    processed_files += 1
                except Exception as e:
                    print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}")
    
    print(f"\n{'='*60}")
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {processed_files}")
    print(f"üìä –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü: {'–í–∫–ª—é—á–µ–Ω–æ' if not args.no_tables else '–û—Ç–∫–ª—é—á–µ–Ω–æ'}")
    print(f"‚úçÔ∏è  –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ: {'–í–∫–ª—é—á–µ–Ω–æ' if not args.no_handwritten else '–û—Ç–∫–ª—é—á–µ–Ω–æ'}")
    print(f"üéÆ GPU: {'–î–∞' if not args.no_gpu and torch.cuda.is_available() else '–ù–µ—Ç'}")


if __name__ == "__main__":
    main()

