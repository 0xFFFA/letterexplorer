#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM-–ø–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Ollama –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
"""

import argparse
import json
import requests
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
import re
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class LLMDocumentParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM —á–µ—Ä–µ–∑ Ollama"""
    
    def __init__(self, ollama_url: str, model: str, token: Optional[str] = None, verify_ssl: bool = True):
        self.ollama_url = ollama_url.rstrip('/')
        self.model = model
        self.token = token
        self.session = requests.Session()
        self.session.verify = verify_ssl
        if token:
            self.session.headers.update({'X-Access-Token': token})
    
    def test_connection(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Ollama"""
        try:
            response = self.session.get(f"{self.ollama_url}/api/tags")
            if response.status_code == 200:
                print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {response.status_code}")
                return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")
            return False
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏"""
        try:
            response = self.session.post(f"{self.ollama_url}/api/show", 
                                       json={"name": self.model})
            if response.status_code == 200:
                return response.json()
            else:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏: {response.status_code}")
                return {}
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏: {e}")
            return {}
    
    def split_text_into_chunks(self, text: str, chunk_size: int = 2000, overlap: int = 200) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ —Å–æ —Å–∫–æ–ª—å–∑—è—â–∏–º –æ–∫–Ω–æ–º"""
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫, –∏—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            if end < len(text):
                # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–∏–º–≤–æ–ª –∫–æ–Ω—Ü–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö overlap
                search_start = max(start + chunk_size - overlap, start)
                sentence_end = text.rfind('.', search_start, end)
                if sentence_end == -1:
                    sentence_end = text.rfind('\n', search_start, end)
                if sentence_end != -1:
                    end = sentence_end + 1
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —á–∞–Ω–∫–∞
            start = max(start + chunk_size - overlap, end)
            
            # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª
            if start >= len(text):
                break
        
        return chunks
    
    def load_prompt_files(self, prompt_dir: Path) -> Dict[str, str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç—ã –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        prompts = {}
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç
        main_prompt_file = prompt_dir / "prompt_main.txt"
        if main_prompt_file.exists():
            prompts["main"] = main_prompt_file.read_text(encoding='utf-8')
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø—ã –±–ª–æ–∫–æ–≤ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        block_types = self.extract_block_types_from_main_prompt(prompts.get("main", ""))
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –ø—Ä–æ–º–ø—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –≤ main
        for block_type in block_types:
            if block_type == "unknown":
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º unknown –±–ª–æ–∫–∏
                
            prompt_file = prompt_dir / f"prompt_{block_type}.txt"
            if prompt_file.exists():
                prompts[block_type] = prompt_file.read_text(encoding='utf-8')
            else:
                print(f"‚ö†Ô∏è –§–∞–π–ª –ø—Ä–æ–º–ø—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_file}")
        
        return prompts
    
    def extract_block_types_from_main_prompt(self, main_prompt: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∏–ø—ã –±–ª–æ–∫–æ–≤ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞"""
        import re
        
        # –ò—â–µ–º –≤—Å–µ "block_type": "—Ç–∏–ø_–±–ª–æ–∫–∞" –≤ –ø—Ä–æ–º–ø—Ç–µ
        pattern = r'"block_type":\s*"([^"]+)"'
        matches = re.findall(pattern, main_prompt)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫
        return list(set(matches))
    
    def get_main_prompt(self, prompts: Dict[str, str]) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ –Ω–∞ –±–ª–æ–∫–∏"""
        return prompts.get('main', '')
    
    def get_specialized_prompt(self, prompts: Dict[str, str], block_type: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç–∏–ø–∞ –±–ª–æ–∫–∞"""
        return prompts.get(block_type, '')
    
    def parse_blocks_from_main_response(self, response: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –±–ª–æ–∫–∏"""
        try:
            # –£–±–∏—Ä–∞–µ–º markdown –∫–æ–¥ –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if '```' in response:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                if json_start != -1 and json_end != -1:
                    response = response[json_start:json_end]
            
            parsed = json.loads(response)
            return parsed.get('blocks', [])
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –±–ª–æ–∫–æ–≤: {e}")
            return []
    
    def call_ollama(self, prompt: str, context: str = "") -> Optional[str]:
        """–í—ã–∑—ã–≤–∞–µ—Ç Ollama API"""
        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            full_prompt = f"{prompt}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}" if context else prompt
            
            payload = {
                "model": self.model,
                "prompt": full_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    "top_p": 0.9
                }
            }
            
            response = self.session.post(f"{self.ollama_url}/api/generate", 
                                       json=payload, 
                                       timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '').strip()
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ Ollama: {e}")
            return None
    
    def process_chunk_with_smart_prompt(self, chunk: str, prompt_sections: Dict[str, str]) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —á–∞–Ω–∫ —Å —É–º–Ω—ã–º –≤—ã–±–æ—Ä–æ–º –ø—Ä–æ–º–ø—Ç–∞"""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —á–∞–Ω–∫–∞
        chunk_type = self.determine_chunk_type(chunk)
        print(f"  –¢–∏–ø —á–∞–Ω–∫–∞: {chunk_type}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ–º–ø—Ç
        prompt = self.get_prompt_for_chunk_type(prompt_sections, chunk_type)
        
        if not prompt:
            print(f"  ‚ö†Ô∏è –ü—Ä–æ–º–ø—Ç –¥–ª—è —Ç–∏–ø–∞ '{chunk_type}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return {}
        
        print(f"  –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç–∏–ø–∞: {chunk_type}")
        
        # –í—ã–∑—ã–≤–∞–µ–º Ollama —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –ø—Ä–æ–º–ø—Ç–æ–º
        result = self.call_ollama(prompt, chunk)
        
        if result:
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                parsed_result = json.loads(result)
                return parsed_result
            except json.JSONDecodeError:
                # –ï—Å–ª–∏ –Ω–µ JSON, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç
                return {"raw_result": result}
        
        return {}
    
    def process_document_two_stage(self, content: str, prompts: Dict[str, str], file_path: Path) -> Dict[str, Any]:
        """–î–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        print("üîÑ –≠—Ç–∞–ø 1: –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏...")
        
        # –≠—Ç–∞–ø 1: –ü–æ–ª—É—á–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –±–ª–æ–∫–∏
        main_prompt = self.get_main_prompt(prompts)
        if not main_prompt:
            print("‚ùå –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return {}
        
        # –í—ã–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ –Ω–∞ –±–ª–æ–∫–∏
        main_response = self.call_ollama(main_prompt, content)
        if not main_response:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–±–∏–≤–∫—É –Ω–∞ –±–ª–æ–∫–∏")
            return {}
        
        # –ü–∞—Ä—Å–∏–º –±–ª–æ–∫–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞
        blocks = self.parse_blocks_from_main_response(main_response)
        if not blocks:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –±–ª–æ–∫–∏")
            return {}
        
        print(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –±–ª–æ–∫–æ–≤: {len(blocks)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–µ—Ä–≤–æ–≥–æ —ç—Ç–∞–ø–∞
        intermediate_file = file_path.parent / f"{file_path.stem}.tmp.json"
        intermediate_data = {
            "file_info": {
                "filename": file_path.name,
                "stage": "blocks_extraction",
                "total_blocks": len(blocks)
            },
            "blocks": blocks
        }
        
        try:
            with open(intermediate_file, 'w', encoding='utf-8') as f:
                json.dump(intermediate_data, f, ensure_ascii=False, indent=2)
            print(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {intermediate_file}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
        
        # –≠—Ç–∞–ø 2: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –±–ª–æ–∫ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
        print("üîÑ –≠—Ç–∞–ø 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–ª–æ–∫–æ–≤ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏...")
        
        final_results = {}
        unknown_blocks = []
        
        for i, block in enumerate(blocks):
            block_type = block.get('block_type', '')
            block_content = block.get('content', '')
            
            print(f"  üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–ª–æ–∫ {i+1}/{len(blocks)}: {block_type}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –±–ª–æ–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º
            if block_type == 'unknown':
                print(f"    ‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –±–ª–æ–∫ –Ω–∞–π–¥–µ–Ω, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ .err —Ñ–∞–π–ª")
                unknown_blocks.append({
                    "block_index": i + 1,
                    "content": block_content,
                    "start_marker": block.get('start_marker', ''),
                    "end_marker": block.get('end_marker', '')
                })
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            specialized_prompt = self.get_specialized_prompt(prompts, block_type)
            if not specialized_prompt:
                print(f"    ‚ö†Ô∏è –ü—Ä–æ–º–ø—Ç –¥–ª—è —Ç–∏–ø–∞ '{block_type}' –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ .err —Ñ–∞–π–ª")
                unknown_blocks.append({
                    "block_index": i + 1,
                    "block_type": block_type,
                    "content": block_content,
                    "start_marker": block.get('start_marker', ''),
                    "end_marker": block.get('end_marker', ''),
                    "reason": f"–ü—Ä–æ–º–ø—Ç –¥–ª—è —Ç–∏–ø–∞ '{block_type}' –Ω–µ –Ω–∞–π–¥–µ–Ω"
                })
                continue
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–ª–æ–∫
            block_result = self.call_ollama(specialized_prompt, block_content)
            if block_result:
                try:
                    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    parsed_result = json.loads(block_result)
                    final_results.update(parsed_result)
                except json.JSONDecodeError:
                    # –ï—Å–ª–∏ –Ω–µ JSON, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç
                    final_results[f"{block_type}_raw"] = block_result
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–ª–æ–∫–∞–º–∏
            time.sleep(0.5)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±–ª–æ–∫–∏ –≤ .err —Ñ–∞–π–ª
        if unknown_blocks:
            error_file = file_path.parent / f"{file_path.stem}.err"
            error_data = {
                "file_info": {
                    "filename": file_path.name,
                    "processing_stage": "unknown_blocks",
                    "total_unknown_blocks": len(unknown_blocks)
                },
                "unknown_blocks": unknown_blocks
            }
            
            try:
                with open(error_file, 'w', encoding='utf-8') as f:
                    json.dump(error_data, f, ensure_ascii=False, indent=2)
                print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±–ª–æ–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {error_file}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è .err —Ñ–∞–π–ª–∞: {e}")
        
        return final_results
    
    def process_file(self, file_path: Path, prompt_dir: Path) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª"""
        print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: {file_path.name}")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            return {}
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        prompts = self.load_prompt_files(prompt_dir)
        if not prompts:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã")
            return {}
        
        print(f"üìù –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–º–ø—Ç–æ–≤: {len(prompts)}")
        for prompt_type in prompts.keys():
            print(f"  - {prompt_type}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        final_results = self.process_document_two_stage(content, prompts, file_path)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        all_results = {
            "file_info": {
                "filename": file_path.name,
                "processing_method": "two_stage_separate_prompts",
                "total_prompts": len(prompts)
            },
            "extracted_data": final_results
        }
        
        return all_results
    
    def save_results(self, results: Dict[str, Any], output_path: Path):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")


def main():
    parser = argparse.ArgumentParser(description='LLM-–ø–∞—Ä—Å–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ Ollama')
    parser.add_argument('--file', '-f', required=True,
                       help='–ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--prompt-dir', '-p', default='prompts',
                       help='–ö–∞—Ç–∞–ª–æ–≥ —Å —Ñ–∞–π–ª–∞–º–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: prompts)')
    parser.add_argument('--output', '-o', 
                       help='–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –∏–º—è_—Ñ–∞–π–ª–∞.json)')
    parser.add_argument('--ollama-url', default='http://localhost:11434',
                       help='URL Ollama —Å–µ—Ä–≤–µ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: http://localhost:11434)')
    parser.add_argument('--model', '-m', required=True,
                       help='–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Ollama')
    parser.add_argument('--token', '-t',
                       help='–¢–æ–∫–µ–Ω –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)')
    parser.add_argument('--chunk-size', type=int, default=2000,
                       help='–†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 2000)')
    parser.add_argument('--overlap', type=int, default=200,
                       help='–†–∞–∑–º–µ—Ä –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200)')
    parser.add_argument('--no-ssl-verify', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞')
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
    input_file = Path(args.file)
    if not input_file.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_file}")
        return
    
    prompt_dir = Path(args.prompt_dir)
    if not prompt_dir.exists():
        print(f"‚ùå –ö–∞—Ç–∞–ª–æ–≥ –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_dir}")
        return
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    parser_instance = LLMDocumentParser(args.ollama_url, args.model, args.token, 
                                      verify_ssl=not args.no_ssl_verify)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
    if not parser_instance.test_connection():
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
    model_info = parser_instance.get_model_info()
    if model_info:
        print(f"ü§ñ –ú–æ–¥–µ–ª—å: {args.model}")
        if 'parameter_size' in model_info:
            print(f"üìä –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: {model_info['parameter_size']}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
    if args.output:
        output_file = Path(args.output)
    else:
        output_file = input_file.parent / f"{input_file.stem}.json"
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")
    results = parser_instance.process_file(input_file, prompt_dir)
    
    if results:
        parser_instance.save_results(results, output_file)
        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç: {output_file}")
    else:
        print(f"\n‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")


if __name__ == "__main__":
    main()
