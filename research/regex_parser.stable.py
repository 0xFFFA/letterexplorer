#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Regex-–ø–∞—Ä—Å–µ—Ä —Å LLM-–≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
–õ–æ–≥–∏–∫–∞:
1. LLM –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã
2. –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ .regex —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
3. –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫ —Ç–µ–∫—Å—Ç—É –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON
"""

import argparse
import json
import re
import requests
from pathlib import Path
from typing import Dict, List, Any, Optional
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class RegexGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM"""
    
    def __init__(self, ollama_url: str, model: str, token: Optional[str] = None, verify_ssl: bool = True):
        self.ollama_url = ollama_url.rstrip('/')
        self.model = model
        self.token = token
        self.session = requests.Session()
        self.session.verify = verify_ssl
        if token:
            self.session.headers.update({'X-Access-Token': token})
    
    def call_ollama(self, prompt: str) -> Optional[str]:
        """–í—ã–∑—ã–≤–∞–µ—Ç Ollama API"""
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,
                    "top_p": 0.9
                }
            }
            
            response = self.session.post(f"{self.ollama_url}/api/generate", 
                                       json=payload, 
                                       timeout=120)
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '').strip()
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ Ollama: {e}")
            return None
    
    def generate_regex_patterns(self, text: str) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        
        prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º –∏ –ø–∞—Ä—Å–∏–Ω–≥—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ —Å–æ–∑–¥–∞–π –ö–û–ù–¢–ï–ö–°–¢–ù–´–ï —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.

–¢–ï–ö–°–¢ –î–û–ö–£–ú–ï–ù–¢–ê:
{text[:4000]}  

–ó–ê–î–ê–ß–ê:
–°–æ–∑–¥–∞–π JSON —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:

1. –ú–ï–¢–ê–î–ê–ù–ù–´–ï –î–û–ö–£–ú–ï–ù–¢–ê:
   - –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞: –≤ –Ω–∞—á–∞–ª–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞, —Ñ–æ—Ä–º–∞—Ç "–¶–¶- –¶–¶–¶–¶" (–Ω–∞–ø—Ä–∏–º–µ—Ä: "01- 0530")
   - –î–∞—Ç–∞: –ø–æ—Å–ª–µ –Ω–æ–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞, —Ñ–æ—Ä–º–∞—Ç "–ú–ú.–ì–ì–ì–ì" (–Ω–∞–ø—Ä–∏–º–µ—Ä: "04.2025")
   - –°–ø–∏—Å–æ–∫ –∞–¥—Ä–µ—Å–∞—Ç–æ–≤: –≤—Å–µ —Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å "–ù–∞—á–∞–ª—å–Ω–∏–∫—É"

2. –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –ü–ê–†–ê–ú–ï–¢–†–´:
   - –ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏: –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞ "—Å—Ç–∞–ª–∏ –º–∞—Ä–∫–∏" (–Ω–∞–ø—Ä–∏–º–µ—Ä: "6856")
   - –ö–æ–¥ –û–≠–ú–ö: –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞ "–∫–æ–¥ –û–≠–ú–ö"
   - –≠–∫—Å–ø–æ—Ä—Ç–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞ "—ç–∫—Å–ø–æ—Ä—Ç–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ"
   - –£—Å–ª–æ–≤–Ω—ã–π –∞–Ω–∞–ª–æ–≥: –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞ "—É—Å–ª–æ–≤–Ω—ã–π –∞–Ω–∞–ª–æ–≥"

3. –¢–ê–ë–õ–ò–¶–ê 1 - –•–ò–ú–ò–ß–ï–°–ö–ò–ô –°–û–°–¢–ê–í:
   –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã:
   ```
   –¢–∞–±–ª–∏—Ü–∞
   1
   –°    Si   Mn   S    Cr   Ni   Cu   Al
   –†–µ–∫–æ–º–µ–Ω–¥: 0,42 0,25 0,85 0,028 1,05 0,025 0,19
   –ê—Ç—Ç–µ—Å—Ç–∞—Ç: 0,40 0,15 0,80 0,020 1,00 –Ω.–±. –Ω.–±. 0,015 0,18
   –≠–°–ü–¶:     0,45 0,30 0,90 0,035 0,025 1,10 0,25 0,20 0,030 0,25
   ```
   
   –ù—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å:
   - –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤ (C, Si, Mn, S, Cr, Ni, Cu, Al)
   - –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ (–†–µ–∫–æ–º–µ–Ω–¥, –ê—Ç—Ç–µ—Å—Ç–∞—Ç, –≠–°–ü–¶): –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –∑–Ω–∞—á–µ–Ω–∏—è

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (—Å—Ç—Ä–æ–≥–æ JSON):
{{
  "metadata": {{
    "document_number": {{
      "pattern": "^(\\d{{2}}- \\d{{4}})",
      "description": "–ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞"
    }},
    "date": {{
      "pattern": "^\\d{{2}}- \\d{{4}}\\n\\d+\\n(\\d{{2}}\\.\\d{{4}})",
      "description": "–î–∞—Ç–∞ –ø–æ—Å–ª–µ –Ω–æ–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"
    }},
    "addressees": {{
      "pattern": "^–ù–∞—á–∞–ª—å–Ω–∏–∫—É ([–ê-–Ø–Å”ò–Ü“¢“í“Æ“∞“ö”®“∫\\-0-9]+)$",
      "description": "–í—Å–µ —Å—Ç—Ä–æ–∫–∏ –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å '–ù–∞—á–∞–ª—å–Ω–∏–∫—É'",
      "flags": ["MULTILINE"]
    }}
  }},
  "technical_params": {{
    "steel_grade": {{
      "pattern": "—Å—Ç–∞–ª–∏ –º–∞—Ä–∫–∏ (\\d+)",
      "description": "–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏ –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞ '—Å—Ç–∞–ª–∏ –º–∞—Ä–∫–∏'"
    }},
    "code_oemk": {{
      "pattern": "–∫–æ–¥ –û–≠–ú–ö\\s*([–∞-—è–ê-–Ø—ë–Åa-zA-Z0-9]+)",
      "description": "–ö–æ–¥ –û–≠–ú–ö –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞ '–∫–æ–¥ –û–≠–ú–ö'"
    }},
    "export_name": {{
      "pattern": "—ç–∫—Å–ø–æ—Ä—Ç–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\\s+([^\\n]+)",
      "description": "–≠–∫—Å–ø–æ—Ä—Ç–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ"
    }},
    "analog": {{
      "pattern": "—É—Å–ª–æ–≤–Ω—ã–π –∞–Ω–∞–ª–æ–≥\\s+([^\\n]+)",
      "description": "–£—Å–ª–æ–≤–Ω—ã–π –∞–Ω–∞–ª–æ–≥"
    }}
  }},
  "tables": [
    {{
      "table_name": "chemical_composition",
      "table_number": "1",
      "description": "–•–∏–º–∏—á–µ—Å–∫–∏–π —Å–æ—Å—Ç–∞–≤ –∏–∑ –¢–∞–±–ª–∏—Ü—ã 1",
      "extraction_method": "structured",
      "structure": {{
        "elements": {{
          "pattern": "–¢–∞–±–ª–∏—Ü–∞\\s*1\\s*([CSiMnCrNiCuAl\\s]+?)\\s*–†–µ–∫–æ–º–µ–Ω–¥",
          "description": "–≠–ª–µ–º–µ–Ω—Ç—ã –º–µ–∂–¥—É '–¢–∞–±–ª–∏—Ü–∞ 1' –∏ '–†–µ–∫–æ–º–µ–Ω–¥'",
          "flags": ["DOTALL"]
        }},
        "recommended": {{
          "pattern": "–†–µ–∫–æ–º–µ–Ω–¥[^\\n]*\\s*([0-9,–Ω\\.–±\\s]+?)\\s*–ê—Ç—Ç–µ—Å—Ç–∞—Ç",
          "description": "–ó–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –†–µ–∫–æ–º–µ–Ω–¥",
          "flags": ["DOTALL"]
        }},
        "certificate": {{
          "pattern": "–ê—Ç—Ç–µ—Å—Ç–∞—Ç[^\\n]*\\s*([0-9,–Ω\\.–±\\s]+?)\\s*–≠–°–ü–¶",
          "description": "–ó–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ê—Ç—Ç–µ—Å—Ç–∞—Ç",
          "flags": ["DOTALL"]
        }},
        "espz": {{
          "pattern": "–≠–°–ü–¶[^\\n]*\\s*([0-9,–Ω\\.–±\\s]+?)\\s*–ü—Ä–∏–º–µ—á–∞–Ω–∏—è",
          "description": "–ó–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –≠–°–ü–¶",
          "flags": ["DOTALL"]
        }}
      }}
    }}
  ]
}}

–í–ê–ñ–ù–û:
- –ò—Å–ø–æ–ª—å–∑—É–π –ö–û–ù–¢–ï–ö–°–¢–ù–´–ï –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—á—Ç–æ –∏–¥—ë—Ç –î–û –∏ –ü–û–°–õ–ï –∏—Å–∫–æ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞)
- –î–ª—è —á–∏—Å–µ–ª —Å –∑–∞–ø—è—Ç–æ–π: \\d+,\\d+
- –î–ª—è —Ñ–ª–∞–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π: MULTILINE, DOTALL, IGNORECASE
- –î–ª—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø: (?P<name>...)
- –£—á–∏—Ç—ã–≤–∞–π OCR –æ—à–∏–±–∫–∏ (–Ω.–±., –Ω.6., H –≤–º–µ—Å—Ç–æ –ù)

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞!
"""
        
        print("ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å –ø–æ–º–æ—â—å—é LLM...")
        response = self.call_ollama(prompt)
        
        if not response:
            return {}
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
        try:
            # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if '```' in response:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                if json_start != -1 and json_end != -1:
                    response = response[json_start:json_end]
            
            # LLM –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å regex —Å –æ–¥–∏–Ω–∞—Ä–Ω—ã–º–∏ —Å–ª–µ—à–∞–º–∏, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ raw string
            # –î–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ JSON –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω—É–∂–Ω–æ —É–¥–≤–æ–∏—Ç—å –≤—Å–µ –±—ç–∫—Å–ª–µ—à–∏ –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö
            import re as re_module
            
            # –ò—â–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "pattern": "..." –∏ —É–¥–≤–∞–∏–≤–∞–µ–º –≤ –Ω–∏—Ö –±—ç–∫—Å–ª–µ—à–∏
            def fix_pattern(match):
                pattern_value = match.group(1)
                # –£–¥–≤–∞–∏–≤–∞–µ–º –≤—Å–µ –±—ç–∫—Å–ª–µ—à–∏
                pattern_value = pattern_value.replace('\\', '\\\\')
                return f'"pattern": "{pattern_value}"'
            
            response = re_module.sub(r'"pattern":\s*"([^"]*)"', fix_pattern, response)
            
            patterns = json.loads(response)
            return patterns
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–û—Ç–≤–µ—Ç LLM:\n{response[:500]}...")
            return {}


class RegexParser:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫ —Ç–µ–∫—Å—Ç—É"""
    
    def __init__(self, patterns: Dict[str, Any]):
        self.patterns = patterns
    
    def extract_with_pattern(self, text: str, pattern_info: Dict[str, Any]) -> Any:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –æ–¥–Ω–æ–º—É –ø–∞—Ç—Ç–µ—Ä–Ω—É"""
        pattern = pattern_info.get('pattern', '')
        flags_list = pattern_info.get('flags', [])
        
        if not pattern:
            return None
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–ª–∞–≥–∏
        flags = 0
        if 'MULTILINE' in flags_list:
            flags |= re.MULTILINE
        if 'IGNORECASE' in flags_list:
            flags |= re.IGNORECASE
        if 'DOTALL' in flags_list:
            flags |= re.DOTALL
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã
            if '(?P<' in pattern:
                match = re.search(pattern, text, flags)
                if match:
                    return match.groupdict()
            else:
                # –ò—â–µ–º –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                matches = re.findall(pattern, text, flags)
                if matches:
                    # –ï—Å–ª–∏ –æ–¥–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä–æ–∫—É
                    # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ - —Å–ø–∏—Å–æ–∫
                    return matches[0] if len(matches) == 1 else matches
        except re.error as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ regex –ø–∞—Ç—Ç–µ—Ä–Ω–µ: {e}")
            print(f"   –ü–∞—Ç—Ç–µ—Ä–Ω: {pattern}")
        
        return None
    
    def extract_metadata(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ"""
        metadata = {}
        
        if 'metadata' not in self.patterns:
            return metadata
        
        for key, pattern_info in self.patterns['metadata'].items():
            result = self.extract_with_pattern(text, pattern_info)
            if result:
                metadata[key] = result
        
        return metadata
    
    def extract_technical_params(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"""
        params = {}
        
        if 'technical_params' not in self.patterns:
            return params
        
        for key, pattern_info in self.patterns['technical_params'].items():
            result = self.extract_with_pattern(text, pattern_info)
            if result:
                params[key] = result
        
        return params
    
    def extract_table(self, text: str, table_info: Dict[str, Any]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–¥–Ω—É —Ç–∞–±–ª–∏—Ü—É"""
        table_data = {
            "table_name": table_info.get('table_name', 'unknown'),
            "table_number": table_info.get('table_number', ''),
            "description": table_info.get('description', ''),
            "columns": [],
            "rows": {},
            "data": {}
        }
        
        extraction_method = table_info.get('extraction_method', 'structured')
        
        # –ú–µ—Ç–æ–¥ 1: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ (–¥–ª—è –¢–∞–±–ª–∏—Ü—ã 1)
        if extraction_method == 'structured' and 'structure' in table_info:
            structure = table_info['structure']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã (–∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤)
            if 'elements' in structure:
                elements_result = self.extract_with_pattern(text, structure['elements'])
                if elements_result:
                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                    elements_text = elements_result if isinstance(elements_result, str) else str(elements_result)
                    table_data['columns'] = [elem.strip() for elem in elements_text.split() if elem.strip()]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
            for row_name in ['recommended', 'certificate', 'espz']:
                if row_name in structure:
                    row_result = self.extract_with_pattern(text, structure[row_name])
                    if row_result:
                        row_text = row_result if isinstance(row_result, str) else str(row_result)
                        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è
                        values = []
                        for val in row_text.split():
                            val = val.strip()
                            if val and (val[0].isdigit() or val.startswith('–Ω')):
                                values.append(val)
                        table_data['rows'][row_name] = values
        
        # –ú–µ—Ç–æ–¥ 2: –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å –æ–¥–Ω–∏–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º (–¥–ª—è –¢–∞–±–ª–∏—Ü—ã 2)
        elif extraction_method == 'simple' and 'pattern' in table_info:
            result = self.extract_with_pattern(
                text,
                {
                    'pattern': table_info['pattern'],
                    'flags': table_info.get('flags', [])
                }
            )
            if result:
                # –†–µ–∑—É–ª—å—Ç–∞—Ç - –∫–æ—Ä—Ç–µ–∂ –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –≥—Ä—É–ø–ø
                if isinstance(result, tuple):
                    table_data['raw_data'] = list(result)
                else:
                    table_data['raw_data'] = result
        
        # –ú–µ—Ç–æ–¥ 3: –¢–∞–±–ª–∏—Ü–∞ 2 - —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–π —Ä–µ–∂–∏–º
        elif extraction_method == 'structured_table_2' and 'pattern' in table_info:
            result = self.extract_with_pattern(text, {
                'pattern': table_info['pattern'],
                'flags': table_info.get('flags', [])
            })
            if result:
                lines = result.strip().split('\n')
                # –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏ - –∑–∞–≥–æ–ª–æ–≤–∫–∏, –æ—Å—Ç–∞–ª—å–Ω—ã–µ - –∑–Ω–∞—á–µ–Ω–∏—è
                if len(lines) >= 6:
                    table_data['headers'] = [lines[0].strip(), lines[1].strip(), lines[2].strip()]
                    table_data['values'] = [[lines[3].strip(), lines[4].strip()],
                                           [lines[5].strip(), lines[6].strip()],
                                           [lines[7].strip(), lines[8].strip()]]
                else:
                    table_data['raw_text'] = result
        
        # –ú–µ—Ç–æ–¥ 4: –¢–∞–±–ª–∏—Ü–∞ 3 - –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ
        elif extraction_method == 'key_value_table' and 'pattern' in table_info:
            result = self.extract_with_pattern(text, {
                'pattern': table_info['pattern'],
                'flags': table_info.get('flags', [])
            })
            if result:
                lines = [line.strip() for line in result.strip().split('\n') if line.strip()]
                table_data['data'] = {}
                # –ü–∞—Ä—Å–∏–º –∫–∞–∫ –ø–∞—Ä—ã –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ
                i = 0
                while i < len(lines):
                    if i + 1 < len(lines):
                        key = lines[i]
                        value = lines[i+1]
                        # –ï—Å–ª–∏ –∫–ª—é—á –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∞ –∑–Ω–∞—á–µ–Ω–∏–µ - –∫–∞–∫ –¥–∞–Ω–Ω—ã–µ
                        if not value.startswith('N') and not value.startswith('–î'):
                            table_data['data'][key] = value
                            i += 2
                        else:
                            i += 1
                    else:
                        i += 1
        
        # –ú–µ—Ç–æ–¥ 5: –¢–∞–±–ª–∏—Ü–∞ 4 - –¥–∏–∞–º–µ—Ç—Ä—ã –∏ –¥–æ–ø—É—Å–∫–∏
        elif extraction_method == 'structured_table_4' and 'pattern' in table_info:
            result = self.extract_with_pattern(text, {
                'pattern': table_info['pattern'],
                'flags': table_info.get('flags', [])
            })
            if result:
                lines = result.strip().split('\n')
                table_data['headers'] = []
                table_data['rows'] = []
                
                # –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ - –∑–∞–≥–æ–ª–æ–≤–∫–∏
                header_lines = []
                data_started = False
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã –∏ –∑–Ω–∞–∫–∏, —ç—Ç–æ –¥–∞–Ω–Ω—ã–µ
                    if line.replace('+', '').replace(',', '').replace('.', '').replace('-', '').replace(' ', '').isdigit() or \
                       (line.isdigit() and int(line) >= 85):
                        data_started = True
                    
                    if not data_started:
                        header_lines.append(line)
                    else:
                        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å —Å—Ç—Ä–æ–∫—É –¥–∞–Ω–Ω—ã—Ö
                        parts = line.split()
                        if len(parts) >= 3:
                            table_data['rows'].append(parts)
                
                table_data['headers'] = header_lines
        
        # –ú–µ—Ç–æ–¥ 6: –¢–∞–±–ª–∏—Ü–∞ 5 - –ø—Ä–æ–∫–∞–ª–∏–≤–∞–µ–º–æ—Å—Ç—å
        elif extraction_method == 'structured_table_5' and 'pattern' in table_info:
            result = self.extract_with_pattern(text, {
                'pattern': table_info['pattern'],
                'flags': table_info.get('flags', [])
            })
            if result:
                lines = result.strip().split('\n')
                table_data['data'] = {}
                
                # –°–æ–±–∏—Ä–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
                distances = []
                min_values = []
                max_values = []
                
                current_list = None
                for line in lines:
                    line = line.strip()
                    if '–ü–æ–ª–æ—Å–∞ –ø—Ä–æ–∫–∞–ª–∏–≤–∞–µ–º–æ—Å—Ç–∏' in line:
                        continue
                    elif line == 'MM':
                        current_list = distances
                    elif line == 'min':
                        current_list = min_values
                    elif line == 'HRC':
                        continue
                    elif line == 'max':
                        current_list = max_values
                    elif line and current_list is not None:
                        # –†–∞–∑–±–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É –Ω–∞ —á–∏—Å–ª–∞
                        parts = line.split()
                        for part in parts:
                            if part.replace(',', '').replace('.', '').isdigit():
                                current_list.append(part)
                
                table_data['distances_mm'] = distances
                table_data['min_hrc'] = min_values
                table_data['max_hrc'] = max_values
        
        # –ú–µ—Ç–æ–¥ 7: –¢–∞–±–ª–∏—Ü–∞ 6 - —Å—Ç–µ–ø–µ–Ω—å –æ–±–∂–∞—Ç–∏—è
        elif extraction_method == 'structured_table_6' and 'pattern' in table_info:
            result = self.extract_with_pattern(text, {
                'pattern': table_info['pattern'],
                'flags': table_info.get('flags', [])
            })
            if result:
                lines = result.strip().split('\n')
                table_data['data'] = []
                
                # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
                current_row = []
                for line in lines:
                    line = line.strip()
                    if not line or line == ';':
                        continue
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
                    if '–î–∏–∞–º–µ—Ç—Ä' in line or '–°—Ç–µ–ø–µ–Ω—å' in line or '–ø—Ä–æ–∫–∞—Ç–∞' in line or '–æ–±–∂–∞—Ç–∏—è' in line:
                        continue
                    
                    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Å–ª–∞
                    parts = line.split()
                    for part in parts:
                        if part.replace(',', '').replace('.', '').isdigit():
                            current_row.append(part)
                            if len(current_row) == 2:
                                table_data['data'].append({
                                    'diameter_mm': current_row[0],
                                    'compression_degree': current_row[1]
                                })
                                current_row = []
        
        # –ú–µ—Ç–æ–¥ 8: –¢–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ (fallback)
        elif extraction_method == 'text_block' and 'pattern' in table_info:
            result = self.extract_with_pattern(
                text,
                {
                    'pattern': table_info['pattern'],
                    'flags': table_info.get('flags', [])
                }
            )
            if result:
                table_data['raw_text'] = result if isinstance(result, str) else str(result)
        
        # –°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥: header_pattern –∏ value_patterns
        else:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
            if 'header_pattern' in table_info:
                header_result = self.extract_with_pattern(
                    text, 
                    {'pattern': table_info['header_pattern']}
                )
                if header_result:
                    if isinstance(header_result, list):
                        table_data['columns'] = header_result
                    else:
                        table_data['columns'] = [header_result]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç—Ä–æ–∫
            if 'row_names' in table_info:
                table_data['rows'] = table_info['row_names']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
            if 'value_patterns' in table_info:
                for value_key, value_pattern in table_info['value_patterns'].items():
                    result = self.extract_with_pattern(
                        text,
                        {'pattern': value_pattern}
                    )
                    if result:
                        table_data['data'][value_key] = result
        
        return table_data
    
    def extract_tables(self, text: str) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã"""
        tables = []
        
        if 'tables' not in self.patterns:
            return tables
        
        for table_info in self.patterns['tables']:
            table_data = self.extract_table(text, table_info)
            tables.append(table_data)
        
        return tables
    
    def extract_sections(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ä–∞–∑–¥–µ–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        sections = {}
        
        if 'sections' not in self.patterns:
            return sections
        
        for section_name, pattern_info in self.patterns['sections'].items():
            extraction_method = pattern_info.get('extraction_method', 'simple')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª–∞
            result = self.extract_with_pattern(text, pattern_info)
            
            if not result:
                continue
            
            # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –ø–æ–¥—Ä–∞–∑–¥–µ–ª—ã
            if extraction_method == 'structured_subsections' and 'subsection_pattern' in pattern_info:
                subsections = {}
                subsection_pattern = pattern_info['subsection_pattern']
                
                # –ò—â–µ–º –≤—Å–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1.1, 1.2, 2.1, 2.2...)
                import re as re_module
                matches = re_module.finditer(subsection_pattern, result, re_module.MULTILINE | re_module.DOTALL)
                
                for match in matches:
                    subsection_number = match.group(1).strip()
                    subsection_content = match.group(2).strip()
                    subsections[subsection_number] = subsection_content
                
                if subsections:
                    sections[section_name] = {
                        "full_text": result,
                        "subsections": subsections
                    }
                else:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–±–∏—Ç—å –Ω–∞ –ø–æ–¥—Ä–∞–∑–¥–µ–ª—ã, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    sections[section_name] = result
            else:
                sections[section_name] = result
        
        return sections
    
    def parse_document(self, text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –≤–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç"""
        print("üìÑ –ü—Ä–∏–º–µ–Ω—è–µ–º regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫ —Ç–µ–∫—Å—Ç—É...")
        
        result = {
            "metadata": self.extract_metadata(text),
            "technical_params": self.extract_technical_params(text),
            "sections": self.extract_sections(text),
            "tables": self.extract_tables(text)
        }
        
        return result


def save_regex_patterns(patterns: Dict[str, Any], output_file: Path):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ .regex —Ñ–∞–π–ª"""
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(patterns, f, ensure_ascii=False, indent=2)
        print(f"üíæ Regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
        print(f"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏!")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")


def load_regex_patterns(regex_file: Path) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ .regex —Ñ–∞–π–ª–∞"""
    try:
        with open(regex_file, 'r', encoding='utf-8') as f:
            patterns = json.load(f)
        print(f"‚úÖ Regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {regex_file}")
        return patterns
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        return {}


def save_results(results: Dict[str, Any], output_file: Path):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON"""
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")


def main():
    parser = argparse.ArgumentParser(
        description='Regex-–ø–∞—Ä—Å–µ—Ä —Å LLM-–≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤'
    )
    parser.add_argument('--file', '-f', required=True,
                       help='–ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--mode', '-m', 
                       choices=['generate', 'apply', 'both'],
                       default='both',
                       help='–†–µ–∂–∏–º: generate (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è regex), apply (–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ), both (–æ–±–∞)')
    parser.add_argument('--regex-file', '-r',
                       help='–ü—É—Ç—å –∫ .regex —Ñ–∞–π–ª—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –∏–º—è_—Ñ–∞–π–ª–∞.regex)')
    parser.add_argument('--output', '-o',
                       help='–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –∏–º—è_—Ñ–∞–π–ª–∞_parsed.json)')
    parser.add_argument('--ollama-url', default='http://localhost:11434',
                       help='URL Ollama —Å–µ—Ä–≤–µ—Ä–∞')
    parser.add_argument('--model', required=True,
                       help='–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Ollama')
    parser.add_argument('--token',
                       help='–¢–æ–∫–µ–Ω –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏')
    parser.add_argument('--no-ssl-verify', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É SSL')
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
    input_file = Path(args.file)
    if not input_file.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_file}")
        return
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤
    if args.regex_file:
        regex_file = Path(args.regex_file)
    else:
        regex_file = input_file.parent / f"{input_file.stem}.regex"
    
    if args.output:
        output_file = Path(args.output)
    else:
        output_file = input_file.parent / f"{input_file.stem}_parsed.json"
    
    # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            text = f.read()
        print(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {input_file.name} ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return
    
    patterns = {}
    
    # –†–ï–ñ–ò–ú 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    if args.mode in ['generate', 'both']:
        print("\n" + "="*60)
        print("üîÑ –≠–¢–ê–ü 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
        print("="*60)
        
        generator = RegexGenerator(
            args.ollama_url, 
            args.model, 
            args.token,
            verify_ssl=not args.no_ssl_verify
        )
        
        patterns = generator.generate_regex_patterns(text)
        
        if patterns:
            save_regex_patterns(patterns, regex_file)
            print("\n‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã!")
            print(f"üìù –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª: {regex_file}")
            print("   –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤—Ä—É—á–Ω—É—é.")
        else:
            print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
            if args.mode == 'both':
                return
    
    # –†–ï–ñ–ò–ú 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    if args.mode in ['apply', 'both']:
        print("\n" + "="*60)
        print("üîÑ –≠–¢–ê–ü 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
        print("="*60)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–µ—Å–ª–∏ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∏ —Ç–æ–ª—å–∫–æ —á—Ç–æ)
        if args.mode == 'apply':
            if not regex_file.exists():
                print(f"‚ùå –§–∞–π–ª —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {regex_file}")
                print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å --mode generate")
                return
            patterns = load_regex_patterns(regex_file)
        
        if not patterns:
            print("‚ùå –ù–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è")
            return
        
        # –ü–∞—Ä—Å–∏–º –¥–æ–∫—É–º–µ–Ω—Ç
        regex_parser = RegexParser(patterns)
        results = regex_parser.parse_document(text)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        final_results = {
            "file_info": {
                "source_file": input_file.name,
                "regex_file": regex_file.name,
                "parsing_method": "regex_llm_generated"
            },
            "extracted_data": results
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        save_results(final_results, output_file)
        
        print("\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç: {output_file}")


if __name__ == "__main__":
    main()

