#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Regex-–ø–∞—Ä—Å–µ—Ä —Å LLM-–≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
–õ–æ–≥–∏–∫–∞:
1. LLM –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã
2. –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ .regex —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
3. –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫ —Ç–µ–∫—Å—Ç—É –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON
"""

import argparse
import json
import re
import requests
from pathlib import Path
from typing import Dict, List, Any, Optional
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class RegexGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM"""
    
    def __init__(self, ollama_url: str, model: str, token: Optional[str] = None, verify_ssl: bool = True):
        self.ollama_url = ollama_url.rstrip('/')
        self.model = model
        self.token = token
        self.session = requests.Session()
        self.session.verify = verify_ssl
        if token:
            self.session.headers.update({'X-Access-Token': token})
    
    def call_ollama(self, prompt: str) -> Optional[str]:
        """–í—ã–∑—ã–≤–∞–µ—Ç Ollama API"""
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,
                    "top_p": 0.9
                }
            }
            
            response = self.session.post(f"{self.ollama_url}/api/generate", 
                                       json=payload, 
                                       timeout=120)
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '').strip()
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ Ollama: {e}")
            return None
    
    def generate_regex_patterns(self, text: str) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        full_text = text if len(text) < 15000 else text[:15000]
        
        prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º –∏ –ø–∞—Ä—Å–∏–Ω–≥—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –í–ï–°–¨ —Ç–µ–∫—Å—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ —Å–æ–∑–¥–∞–π –ü–û–õ–ù–´–ô –Ω–∞–±–æ—Ä —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –í–°–ï–• –¥–∞–Ω–Ω—ã—Ö.

–¢–ï–ö–°–¢ –î–û–ö–£–ú–ï–ù–¢–ê:
{full_text}

–ó–ê–î–ê–ß–ê:
–°–æ–∑–¥–∞–π –ü–û–õ–ù–´–ô JSON —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –í–°–ï–• —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞:

1. –ú–ï–¢–ê–î–ê–ù–ù–´–ï –î–û–ö–£–ú–ï–ù–¢–ê
2. –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –ü–ê–†–ê–ú–ï–¢–†–´ (–í–°–ï, —á—Ç–æ –Ω–∞–π–¥—ë—à—å –ø–æ—Å–ª–µ "–∫–æ–¥ –û–≠–ú–ö", "—ç–∫—Å–ø–æ—Ä—Ç–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "—Å—Ç–∞–Ω–¥–∞—Ä—Ç –≤—ã–ø–ª–∞–≤–∫–∏", "–∫–æ–¥ –≤–∏–¥–∞ –ø—Ä–æ–¥—É–∫—Ü–∏–∏")
3. –¢–ï–ö–°–¢–û–í–´–ï –†–ê–ó–î–ï–õ–´ (–Ω–∞–π–¥–∏ –í–°–ï —Ä–∞–∑–¥–µ–ª—ã —Ç–∏–ø–∞ "1. –ü–†–û–ò–ó–í–û–î–°–¢–í–û –ù–õ–ó:", "2. –ü–†–û–ò–ó–í–û–î–°–¢–í–û –ü–†–û–ö–ê–¢–ê", "3. –ö–û–ù–¢–†–û–õ–¨ –ò –ê–¢–¢–ï–°–¢–ê–¶–ò–Ø")
4. –í–°–ï –¢–ê–ë–õ–ò–¶–´ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ (–Ω–∞–π–¥–∏ –∫–∞–∂–¥—É—é "–¢–∞–±–ª–∏—Ü–∞ N" –∏ —Å–æ–∑–¥–∞–π –ø–∞—Ç—Ç–µ—Ä–Ω)

–§–û–†–ú–ê–¢ JSON:

{{
  "metadata": {{
    "document_number": {{
      "pattern": "regex –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–æ–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—É—á–∏—Ç—ã–≤–∞–π '--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ 1 ---')",
      "description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ",
      "flags": ["MULTILINE"]
    }},
    "date": {{
      "pattern": "regex –¥–ª—è –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ –ú–ú.–ì–ì–ì–ì",
      "flags": ["MULTILINE"]
    }},
    "addressees": {{
      "pattern": "regex –¥–ª—è –≤—Å–µ—Ö –∞–¥—Ä–µ—Å–∞—Ç–æ–≤ (—Å—Ç—Ä–æ–∫–∏ '–ù–∞—á–∞–ª—å–Ω–∏–∫—É ...')",
      "flags": ["MULTILINE"]
    }}
  }},
  
  "technical_params": {{
    "steel_grade": {{"pattern": "—Å—Ç–∞–ª–∏ –º–∞—Ä–∫–∏ (\\\\d+)", "description": "..."}},
    "code_oemk": {{"pattern": "–∫–æ–¥ –û–≠–ú–ö\\\\s*([^\\\\n]+)", "flags": ["IGNORECASE"]}},
    "export_name": {{"pattern": "—ç–∫—Å–ø–æ—Ä—Ç–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\\\\s+([^\\\\n]+)", "flags": ["MULTILINE"]}},
    "analog": {{"pattern": "—É—Å–ª–æ–≤–Ω—ã–π –∞–Ω–∞–ª–æ–≥\\\\s+([^\\\\n]+)", "flags": ["MULTILINE"]}},
    "production_code": {{"pattern": "–∫–æ–¥ –≤–∏–¥–∞ –ø—Ä–æ–¥—É–∫—Ü–∏–∏\\\\s+(\\\\d+)", "flags": ["MULTILINE"]}},
    "standard": {{"pattern": "—Å—Ç–∞–Ω–¥–∞—Ä—Ç –≤—ã–ø–ª–∞–≤–∫–∏\\\\s+([^\\\\n]+)", "flags": ["MULTILINE"]}}
  }},
  
  "sections": {{
    "section_1_nlz": {{
      "pattern": "–ü–†–û–ò–ó–í–û–î–°–¢–í–û –ù–õ–ó:([\\\\s\\\\S]+?)(?=2\\\\. –ü–†–û–ò–ó–í–û–î–°–¢–í–û –ü–†–û–ö–ê–¢–ê|–¢–∞–±–ª–∏—Ü–∞ 3)",
      "description": "–†–∞–∑–¥–µ–ª 1: –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –ù–õ–ó",
      "extraction_method": "structured_subsections",
      "subsection_pattern": "^(1\\\\.\\\\d+\\\\.?)\\\\s+([\\\\s\\\\S]+?)(?=^1\\\\.\\\\d+\\\\.|^2\\\\.|$)",
      "flags": ["DOTALL", "MULTILINE"]
    }},
    "section_2_rolling": {{
      "pattern": "2\\\\. –ü–†–û–ò–ó–í–û–î–°–¢–í–û –ü–†–û–ö–ê–¢–ê([\\\\s\\\\S]+?)(?=3\\\\. –ö–û–ù–¢–†–û–õ–¨ –ò –ê–¢–¢–ï–°–¢–ê–¶–ò–Ø)",
      "description": "–†–∞–∑–¥–µ–ª 2: –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –ø—Ä–æ–∫–∞—Ç–∞",
      "extraction_method": "structured_subsections",
      "subsection_pattern": "^(2\\\\.\\\\d+\\\\.?)\\\\s+([\\\\s\\\\S]+?)(?=^2\\\\.\\\\d+\\\\.|^3\\\\.|$)",
      "flags": ["DOTALL", "MULTILINE"]
    }},
    "section_3_control": {{
      "pattern": "3\\\\. –ö–û–ù–¢–†–û–õ–¨ –ò –ê–¢–¢–ï–°–¢–ê–¶–ò–Ø –ü–†–û–ö–ê–¢–ê([\\\\s\\\\S]+?)(?=–¢–∞–±–ª–∏—Ü–∞ 6|–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä)",
      "description": "–†–∞–∑–¥–µ–ª 3: –ö–æ–Ω—Ç—Ä–æ–ª—å –∏ –∞—Ç—Ç–µ—Å—Ç–∞—Ü–∏—è",
      "extraction_method": "structured_subsections",
      "subsection_pattern": "^(3\\\\.\\\\d+\\\\.?)\\\\s+([\\\\s\\\\S]+?)(?=^3\\\\.\\\\d+\\\\.|–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä|$)",
      "flags": ["DOTALL", "MULTILINE"]
    }},
    "signatures": {{
      "pattern": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä\\\\s*\\\\n([^\\\\n]+)",
      "flags": ["MULTILINE"]
    }},
    "distribution_plan": {{
      "pattern": "–ü–ª–∞–Ω —Ä–∞—Å—Å—ã–ª–∫–∏:\\\\s*([^\\\\n]+)",
      "flags": ["MULTILINE"]
    }}
  }},
  
  "tables": [
    {{
      "table_name": "chemical_composition",
      "table_number": "1",
      "description": "–•–∏–º–∏—á–µ—Å–∫–∏–π —Å–æ—Å—Ç–∞–≤",
      "extraction_method": "structured",
      "structure": {{
        "elements": {{
          "pattern": "–¢–∞–±–ª–∏—Ü–∞\\\\s*1\\\\s*\\\\n(–°\\\\s*\\\\n\\\\s*Si\\\\s*\\\\nMn\\\\s*\\\\nS\\\\s*\\\\nCr\\\\s*\\\\nNi\\\\s*\\\\nCu\\\\s*\\\\nAl)",
          "flags": ["MULTILINE"]
        }},
        "recommended": {{
          "pattern": "–†–µ–∫–æ–º–µ–Ω–¥:\\\\s*\\\\n([0-9,\\\\n]+?)\\\\n–ê—Ç—Ç–µ—Å—Ç–∞—Ç",
          "flags": ["MULTILINE"]
        }},
        "certificate": {{
          "pattern": "–ê—Ç—Ç–µ—Å—Ç–∞—Ç\\\\.\\\\s*\\\\n([0-9,–Ω\\\\.–±\\\\s\\\\n]+?)\\\\n–≠–°–ü–¶",
          "flags": ["MULTILINE"]
        }},
        "espz": {{
          "pattern": "–≠–°–ü–¶\\\\s*\\\\n([0-9,\\\\n]+?)\\\\n–ü—Ä–∏–º–µ—á–∞–Ω–∏—è",
          "flags": ["MULTILINE"]
        }}
      }}
    }},
    {{
      "table_name": "temperature_regime",
      "table_number": "2",
      "description": "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–π —Ä–µ–∂–∏–º –ø–ª–∞–≤–æ–∫",
      "extraction_method": "structured_table_2",
      "pattern": "–¢–∞–±–ª–∏—Ü–∞ 2\\\\s*\\\\n([\\\\s\\\\S]+?)\\\\n1\\\\.11\\\\.",
      "flags": ["DOTALL"]
    }},
    {{
      "table_name": "material_info",
      "table_number": "3",
      "description": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–∞—Ç–µ—Ä–∏–∞–ª–µ",
      "extraction_method": "key_value_table",
      "pattern": "–¢–∞–±–ª–∏—Ü–∞ 3\\\\s*\\\\n([\\\\s\\\\S]+?)\\\\n2\\\\.1\\\\.",
      "flags": ["DOTALL"]
    }},
    {{
      "table_name": "diameter_tolerances",
      "table_number": "4",
      "description": "–î–∏–∞–º–µ—Ç—Ä –∏ –¥–æ–ø—É—Å–∫–∏",
      "extraction_method": "structured_table_4",
      "pattern": "–¢–∞–±–ª–∏—Ü–∞ 4\\\\s*\\\\n([\\\\s\\\\S]+?)\\\\n–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–∫–∞—Ç–∫—É",
      "flags": ["DOTALL"]
    }},
    {{
      "table_name": "hardenability_band",
      "table_number": "5",
      "description": "–ü–æ–ª–æ—Å–∞ –ø—Ä–æ–∫–∞–ª–∏–≤–∞–µ–º–æ—Å—Ç–∏",
      "extraction_method": "structured_table_5",
      "pattern": "–¢–∞–±–ª–∏—Ü–∞ 5\\\\s*\\\\n([\\\\s\\\\S]+?)\\\\n3\\\\.2\\\\.",
      "flags": ["DOTALL"]
    }},
    {{
      "table_name": "compression_degree",
      "table_number": "6",
      "description": "–°—Ç–µ–ø–µ–Ω—å –æ–±–∂–∞—Ç–∏—è",
      "extraction_method": "structured_table_6",
      "pattern": "–¢–∞–±–ª–∏—Ü–∞ 6\\\\.\\\\s*\\\\n([\\\\s\\\\S]+?)\\\\n–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä",
      "flags": ["DOTALL"]
    }}
  ]
}}

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
1. –ù–∞–π–¥–∏ –í–°–ï —Ä–∞–∑–¥–µ–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ (1., 2., 3., –∏ —Ç.–¥.)
2. –ù–∞–π–¥–∏ –í–°–ï —Ç–∞–±–ª–∏—Ü—ã (–¢–∞–±–ª–∏—Ü–∞ 1, 2, 3, 4, 5, 6...)
3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ —Å–æ–∑–¥–∞–π –ø–∞—Ç—Ç–µ—Ä–Ω —Å extraction_method: "structured_subsections" –∏ subsection_pattern –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –ø–æ–¥–ø—É–Ω–∫—Ç—ã (1.1, 1.2, 2.1, 2.2...)
4. –î–ª—è –∫–∞–∂–¥–æ–π —Ç–∞–±–ª–∏—Ü—ã –æ–ø—Ä–µ–¥–µ–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π extraction_method:
   - "structured" - –¥–ª—è —Ç–∞–±–ª–∏—Ü —Å —á—ë—Ç–∫–∏–º —Ñ–æ—Ä–º–∞—Ç–æ–º (–∫–∞–∫ –¢–∞–±–ª–∏—Ü–∞ 1)
   - "structured_table_N" - –¥–ª—è —Ç–∞–±–ª–∏—Ü —Å–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
   - "key_value_table" - –¥–ª—è —Ç–∞–±–ª–∏—Ü —Å –ø–∞—Ä–∞–º–∏ –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ
5. –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–ª–∞–≥–∏ MULTILINE –∏ DOTALL –≥–¥–µ –Ω—É–∂–Ω–æ
6. –í—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ö–û–ù–¢–ï–ö–°–¢–ù–´–ú–ò (—É—á–∏—Ç—ã–≤–∞–π —á—Ç–æ –∏–¥—ë—Ç –î–û –∏ –ü–û–°–õ–ï)
7. –í JSON –∏—Å–ø–æ–ª—å–∑—É–π –¥–≤–æ–π–Ω—ã–µ —Å–ª–µ—à–∏: \\\\d, \\\\s, \\\\n, –∏ —Ç.–¥.

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON, –±–µ–∑ markdown –±–ª–æ–∫–æ–≤ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞!
"""
        
        print("ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å –ø–æ–º–æ—â—å—é LLM...")
        response = self.call_ollama(prompt)
        
        if not response:
            return {}
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
        try:
            # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if '```' in response:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                if json_start != -1 and json_end != -1:
                    response = response[json_start:json_end]
            
            # LLM –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å regex —Å —Ä–∞–∑–Ω—ã–º —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            import re as re_module
            
            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            def normalize_pattern(match):
                field_name = match.group(1)
                pattern_value = match.group(2)
                
                # –ï—Å–ª–∏ —É–∂–µ –¥–≤–æ–π–Ω–æ–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (\\\\), –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                # –ï—Å–ª–∏ –æ–¥–∏–Ω–∞—Ä–Ω–æ–µ (\\), —É–¥–≤–∞–∏–≤–∞–µ–º
                if '\\\\\\\\' not in pattern_value:  # –ù–µ—Ç —á–µ—Ç–≤–µ—Ä–Ω—ã—Ö —Å–ª–µ—à–µ–π
                    # –ó–∞–º–µ–Ω—è–µ–º –¥–≤–æ–π–Ω—ã–µ –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–π –º–∞—Ä–∫–µ—Ä
                    pattern_value = pattern_value.replace('\\\\', '\x00DOUBLE\x00')
                    # –û–¥–∏–Ω–∞—Ä–Ω—ã–µ —É–¥–≤–∞–∏–≤–∞–µ–º
                    pattern_value = pattern_value.replace('\\', '\\\\')
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–≤–æ–π–Ω—ã–µ –æ–±—Ä–∞—Ç–Ω–æ
                    pattern_value = pattern_value.replace('\x00DOUBLE\x00', '\\\\')
                
                return f'"{field_name}": "{pattern_value}"'
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Å–µ –ø–æ–ª—è pattern –∏ subsection_pattern
            response = re_module.sub(r'"(pattern|subsection_pattern)":\s*"([^"]*)"', normalize_pattern, response)
            
            patterns = json.loads(response)
            return patterns
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–û—Ç–≤–µ—Ç LLM:\n{response[:500]}...")
            return {}


class RegexParser:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫ —Ç–µ–∫—Å—Ç—É"""
    
    def __init__(self, patterns: Dict[str, Any]):
        self.patterns = patterns
    
    def extract_with_pattern(self, text: str, pattern_info: Dict[str, Any]) -> Any:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –æ–¥–Ω–æ–º—É –ø–∞—Ç—Ç–µ—Ä–Ω—É"""
        pattern = pattern_info.get('pattern', '')
        flags_list = pattern_info.get('flags', [])
        
        if not pattern:
            return None
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–ª–∞–≥–∏
        flags = 0
        if 'MULTILINE' in flags_list:
            flags |= re.MULTILINE
        if 'IGNORECASE' in flags_list:
            flags |= re.IGNORECASE
        if 'DOTALL' in flags_list:
            flags |= re.DOTALL
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã
            if '(?P<' in pattern:
                match = re.search(pattern, text, flags)
                if match:
                    return match.groupdict()
            else:
                # –ò—â–µ–º –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                matches = re.findall(pattern, text, flags)
                if matches:
                    # –ï—Å–ª–∏ –æ–¥–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä–æ–∫—É
                    # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ - —Å–ø–∏—Å–æ–∫
                    return matches[0] if len(matches) == 1 else matches
        except re.error as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ regex –ø–∞—Ç—Ç–µ—Ä–Ω–µ: {e}")
            print(f"   –ü–∞—Ç—Ç–µ—Ä–Ω: {pattern}")
        
        return None
    
    def extract_metadata(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ"""
        metadata = {}
        
        if 'metadata' not in self.patterns:
            return metadata
        
        for key, pattern_info in self.patterns['metadata'].items():
            result = self.extract_with_pattern(text, pattern_info)
            if result:
                metadata[key] = result
        
        return metadata
    
    def extract_technical_params(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"""
        params = {}
        
        if 'technical_params' not in self.patterns:
            return params
        
        for key, pattern_info in self.patterns['technical_params'].items():
            result = self.extract_with_pattern(text, pattern_info)
            if result:
                params[key] = result
        
        return params
    
    def extract_table(self, text: str, table_info: Dict[str, Any]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–¥–Ω—É —Ç–∞–±–ª–∏—Ü—É"""
        table_data = {
            "table_name": table_info.get('table_name', 'unknown'),
            "table_number": table_info.get('table_number', ''),
            "description": table_info.get('description', ''),
            "columns": [],
            "rows": {},
            "data": {}
        }
        
        extraction_method = table_info.get('extraction_method', 'structured')
        
        # –ú–µ—Ç–æ–¥ 1: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ (–¥–ª—è –¢–∞–±–ª–∏—Ü—ã 1)
        if extraction_method == 'structured' and 'structure' in table_info:
            structure = table_info['structure']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã (–∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤)
            if 'elements' in structure:
                elements_result = self.extract_with_pattern(text, structure['elements'])
                if elements_result:
                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                    elements_text = elements_result if isinstance(elements_result, str) else str(elements_result)
                    table_data['columns'] = [elem.strip() for elem in elements_text.split() if elem.strip()]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
            for row_name in ['recommended', 'certificate', 'espz']:
                if row_name in structure:
                    row_result = self.extract_with_pattern(text, structure[row_name])
                    if row_result:
                        row_text = row_result if isinstance(row_result, str) else str(row_result)
                        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è
                        values = []
                        for val in row_text.split():
                            val = val.strip()
                            if val and (val[0].isdigit() or val.startswith('–Ω')):
                                values.append(val)
                        table_data['rows'][row_name] = values
        
        # –ú–µ—Ç–æ–¥ 2: –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å –æ–¥–Ω–∏–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º (–¥–ª—è –¢–∞–±–ª–∏—Ü—ã 2)
        elif extraction_method == 'simple' and 'pattern' in table_info:
            result = self.extract_with_pattern(
                text,
                {
                    'pattern': table_info['pattern'],
                    'flags': table_info.get('flags', [])
                }
            )
            if result:
                # –†–µ–∑—É–ª—å—Ç–∞—Ç - –∫–æ—Ä—Ç–µ–∂ –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –≥—Ä—É–ø–ø
                if isinstance(result, tuple):
                    table_data['raw_data'] = list(result)
                else:
                    table_data['raw_data'] = result
        
        # –ú–µ—Ç–æ–¥ 3: –¢–∞–±–ª–∏—Ü–∞ 2 - —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–π —Ä–µ–∂–∏–º
        elif extraction_method == 'structured_table_2' and 'pattern' in table_info:
            result = self.extract_with_pattern(text, {
                'pattern': table_info['pattern'],
                'flags': table_info.get('flags', [])
            })
            if result:
                lines = result.strip().split('\n')
                # –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏ - –∑–∞–≥–æ–ª–æ–≤–∫–∏, –æ—Å—Ç–∞–ª—å–Ω—ã–µ - –∑–Ω–∞—á–µ–Ω–∏—è
                if len(lines) >= 6:
                    table_data['headers'] = [lines[0].strip(), lines[1].strip(), lines[2].strip()]
                    table_data['values'] = [[lines[3].strip(), lines[4].strip()],
                                           [lines[5].strip(), lines[6].strip()],
                                           [lines[7].strip(), lines[8].strip()]]
                else:
                    table_data['raw_text'] = result
        
        # –ú–µ—Ç–æ–¥ 4: –¢–∞–±–ª–∏—Ü–∞ 3 - –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ
        elif extraction_method == 'key_value_table' and 'pattern' in table_info:
            result = self.extract_with_pattern(text, {
                'pattern': table_info['pattern'],
                'flags': table_info.get('flags', [])
            })
            if result:
                lines = [line.strip() for line in result.strip().split('\n') if line.strip()]
                table_data['data'] = {}
                # –ü–∞—Ä—Å–∏–º –∫–∞–∫ –ø–∞—Ä—ã –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ
                i = 0
                while i < len(lines):
                    if i + 1 < len(lines):
                        key = lines[i]
                        value = lines[i+1]
                        # –ï—Å–ª–∏ –∫–ª—é—á –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∞ –∑–Ω–∞—á–µ–Ω–∏–µ - –∫–∞–∫ –¥–∞–Ω–Ω—ã–µ
                        if not value.startswith('N') and not value.startswith('–î'):
                            table_data['data'][key] = value
                            i += 2
                        else:
                            i += 1
                    else:
                        i += 1
        
        # –ú–µ—Ç–æ–¥ 5: –¢–∞–±–ª–∏—Ü–∞ 4 - –¥–∏–∞–º–µ—Ç—Ä—ã –∏ –¥–æ–ø—É—Å–∫–∏
        elif extraction_method == 'structured_table_4' and 'pattern' in table_info:
            result = self.extract_with_pattern(text, {
                'pattern': table_info['pattern'],
                'flags': table_info.get('flags', [])
            })
            if result:
                lines = result.strip().split('\n')
                table_data['headers'] = []
                table_data['rows'] = []
                
                # –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ - –∑–∞–≥–æ–ª–æ–≤–∫–∏
                header_lines = []
                data_started = False
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã –∏ –∑–Ω–∞–∫–∏, —ç—Ç–æ –¥–∞–Ω–Ω—ã–µ
                    if line.replace('+', '').replace(',', '').replace('.', '').replace('-', '').replace(' ', '').isdigit() or \
                       (line.isdigit() and int(line) >= 85):
                        data_started = True
                    
                    if not data_started:
                        header_lines.append(line)
                    else:
                        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å —Å—Ç—Ä–æ–∫—É –¥–∞–Ω–Ω—ã—Ö
                        parts = line.split()
                        if len(parts) >= 3:
                            table_data['rows'].append(parts)
                
                table_data['headers'] = header_lines
        
        # –ú–µ—Ç–æ–¥ 6: –¢–∞–±–ª–∏—Ü–∞ 5 - –ø—Ä–æ–∫–∞–ª–∏–≤–∞–µ–º–æ—Å—Ç—å
        elif extraction_method == 'structured_table_5' and 'pattern' in table_info:
            result = self.extract_with_pattern(text, {
                'pattern': table_info['pattern'],
                'flags': table_info.get('flags', [])
            })
            if result:
                lines = result.strip().split('\n')
                table_data['data'] = {}
                
                # –°–æ–±–∏—Ä–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
                distances = []
                min_values = []
                max_values = []
                
                current_list = None
                for line in lines:
                    line = line.strip()
                    if '–ü–æ–ª–æ—Å–∞ –ø—Ä–æ–∫–∞–ª–∏–≤–∞–µ–º–æ—Å—Ç–∏' in line:
                        continue
                    elif line == 'MM':
                        current_list = distances
                    elif line == 'min':
                        current_list = min_values
                    elif line == 'HRC':
                        continue
                    elif line == 'max':
                        current_list = max_values
                    elif line and current_list is not None:
                        # –†–∞–∑–±–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É –Ω–∞ —á–∏—Å–ª–∞
                        parts = line.split()
                        for part in parts:
                            if part.replace(',', '').replace('.', '').isdigit():
                                current_list.append(part)
                
                table_data['distances_mm'] = distances
                table_data['min_hrc'] = min_values
                table_data['max_hrc'] = max_values
        
        # –ú–µ—Ç–æ–¥ 7: –¢–∞–±–ª–∏—Ü–∞ 6 - —Å—Ç–µ–ø–µ–Ω—å –æ–±–∂–∞—Ç–∏—è
        elif extraction_method == 'structured_table_6' and 'pattern' in table_info:
            result = self.extract_with_pattern(text, {
                'pattern': table_info['pattern'],
                'flags': table_info.get('flags', [])
            })
            if result:
                lines = result.strip().split('\n')
                table_data['data'] = []
                
                # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
                current_row = []
                for line in lines:
                    line = line.strip()
                    if not line or line == ';':
                        continue
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
                    if '–î–∏–∞–º–µ—Ç—Ä' in line or '–°—Ç–µ–ø–µ–Ω—å' in line or '–ø—Ä–æ–∫–∞—Ç–∞' in line or '–æ–±–∂–∞—Ç–∏—è' in line:
                        continue
                    
                    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Å–ª–∞
                    parts = line.split()
                    for part in parts:
                        if part.replace(',', '').replace('.', '').isdigit():
                            current_row.append(part)
                            if len(current_row) == 2:
                                table_data['data'].append({
                                    'diameter_mm': current_row[0],
                                    'compression_degree': current_row[1]
                                })
                                current_row = []
        
        # –ú–µ—Ç–æ–¥ 8: –¢–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ (fallback)
        elif extraction_method == 'text_block' and 'pattern' in table_info:
            result = self.extract_with_pattern(
                text,
                {
                    'pattern': table_info['pattern'],
                    'flags': table_info.get('flags', [])
                }
            )
            if result:
                table_data['raw_text'] = result if isinstance(result, str) else str(result)
        
        # –°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥: header_pattern –∏ value_patterns
        else:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
            if 'header_pattern' in table_info:
                header_result = self.extract_with_pattern(
                    text, 
                    {'pattern': table_info['header_pattern']}
                )
                if header_result:
                    if isinstance(header_result, list):
                        table_data['columns'] = header_result
                    else:
                        table_data['columns'] = [header_result]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç—Ä–æ–∫
            if 'row_names' in table_info:
                table_data['rows'] = table_info['row_names']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
            if 'value_patterns' in table_info:
                for value_key, value_pattern in table_info['value_patterns'].items():
                    result = self.extract_with_pattern(
                        text,
                        {'pattern': value_pattern}
                    )
                    if result:
                        table_data['data'][value_key] = result
        
        return table_data
    
    def extract_tables(self, text: str) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã"""
        tables = []
        
        if 'tables' not in self.patterns:
            return tables
        
        for table_info in self.patterns['tables']:
            table_data = self.extract_table(text, table_info)
            tables.append(table_data)
        
        return tables
    
    def extract_sections(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ä–∞–∑–¥–µ–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        sections = {}
        
        if 'sections' not in self.patterns:
            return sections
        
        for section_name, pattern_info in self.patterns['sections'].items():
            extraction_method = pattern_info.get('extraction_method', 'simple')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª–∞
            result = self.extract_with_pattern(text, pattern_info)
            
            if not result:
                continue
            
            # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –ø–æ–¥—Ä–∞–∑–¥–µ–ª—ã
            if extraction_method == 'structured_subsections' and 'subsection_pattern' in pattern_info:
                subsections = {}
                subsection_pattern = pattern_info['subsection_pattern']
                
                # –ò—â–µ–º –≤—Å–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1.1, 1.2, 2.1, 2.2...)
                import re as re_module
                matches = re_module.finditer(subsection_pattern, result, re_module.MULTILINE | re_module.DOTALL)
                
                for match in matches:
                    subsection_number = match.group(1).strip()
                    subsection_content = match.group(2).strip()
                    subsections[subsection_number] = subsection_content
                
                if subsections:
                    sections[section_name] = {
                        "full_text": result,
                        "subsections": subsections
                    }
                else:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–±–∏—Ç—å –Ω–∞ –ø–æ–¥—Ä–∞–∑–¥–µ–ª—ã, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    sections[section_name] = result
            else:
                sections[section_name] = result
        
        return sections
    
    def parse_document(self, text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –≤–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç"""
        print("üìÑ –ü—Ä–∏–º–µ–Ω—è–µ–º regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫ —Ç–µ–∫—Å—Ç—É...")
        
        result = {
            "metadata": self.extract_metadata(text),
            "technical_params": self.extract_technical_params(text),
            "sections": self.extract_sections(text),
            "tables": self.extract_tables(text)
        }
        
        return result


def save_regex_patterns(patterns: Dict[str, Any], output_file: Path):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ .regex —Ñ–∞–π–ª"""
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(patterns, f, ensure_ascii=False, indent=2)
        print(f"üíæ Regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
        print(f"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏!")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")


def load_regex_patterns(regex_file: Path) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ .regex —Ñ–∞–π–ª–∞"""
    try:
        with open(regex_file, 'r', encoding='utf-8') as f:
            patterns = json.load(f)
        print(f"‚úÖ Regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {regex_file}")
        return patterns
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        return {}


def save_results(results: Dict[str, Any], output_file: Path):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON"""
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")


def main():
    parser = argparse.ArgumentParser(
        description='Regex-–ø–∞—Ä—Å–µ—Ä —Å LLM-–≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤'
    )
    parser.add_argument('--file', '-f', required=True,
                       help='–ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--mode', '-m', 
                       choices=['generate', 'apply', 'both'],
                       default='both',
                       help='–†–µ–∂–∏–º: generate (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è regex), apply (–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ), both (–æ–±–∞)')
    parser.add_argument('--regex-file', '-r',
                       help='–ü—É—Ç—å –∫ .regex —Ñ–∞–π–ª—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –∏–º—è_—Ñ–∞–π–ª–∞.regex)')
    parser.add_argument('--output', '-o',
                       help='–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –∏–º—è_—Ñ–∞–π–ª–∞_parsed.json)')
    parser.add_argument('--ollama-url', default='http://localhost:11434',
                       help='URL Ollama —Å–µ—Ä–≤–µ—Ä–∞')
    parser.add_argument('--model', required=True,
                       help='–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Ollama')
    parser.add_argument('--token',
                       help='–¢–æ–∫–µ–Ω –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏')
    parser.add_argument('--no-ssl-verify', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É SSL')
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
    input_file = Path(args.file)
    if not input_file.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_file}")
        return
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤
    if args.regex_file:
        regex_file = Path(args.regex_file)
    else:
        regex_file = input_file.parent / f"{input_file.stem}.regex"
    
    if args.output:
        output_file = Path(args.output)
    else:
        output_file = input_file.parent / f"{input_file.stem}_parsed.json"
    
    # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            text = f.read()
        print(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {input_file.name} ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return
    
    patterns = {}
    
    # –†–ï–ñ–ò–ú 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    if args.mode in ['generate', 'both']:
        print("\n" + "="*60)
        print("üîÑ –≠–¢–ê–ü 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
        print("="*60)
        
        generator = RegexGenerator(
            args.ollama_url, 
            args.model, 
            args.token,
            verify_ssl=not args.no_ssl_verify
        )
        
        patterns = generator.generate_regex_patterns(text)
        
        if patterns:
            save_regex_patterns(patterns, regex_file)
            print("\n‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã!")
            print(f"üìù –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª: {regex_file}")
            print("   –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤—Ä—É—á–Ω—É—é.")
        else:
            print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
            if args.mode == 'both':
                return
    
    # –†–ï–ñ–ò–ú 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    if args.mode in ['apply', 'both']:
        print("\n" + "="*60)
        print("üîÑ –≠–¢–ê–ü 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ regex –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
        print("="*60)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–µ—Å–ª–∏ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∏ —Ç–æ–ª—å–∫–æ —á—Ç–æ)
        if args.mode == 'apply':
            if not regex_file.exists():
                print(f"‚ùå –§–∞–π–ª —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {regex_file}")
                print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å --mode generate")
                return
            patterns = load_regex_patterns(regex_file)
        
        if not patterns:
            print("‚ùå –ù–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è")
            return
        
        # –ü–∞—Ä—Å–∏–º –¥–æ–∫—É–º–µ–Ω—Ç
        regex_parser = RegexParser(patterns)
        results = regex_parser.parse_document(text)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        final_results = {
            "file_info": {
                "source_file": input_file.name,
                "regex_file": regex_file.name,
                "parsing_method": "regex_llm_generated"
            },
            "extracted_data": results
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        save_results(final_results, output_file)
        
        print("\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç: {output_file}")


if __name__ == "__main__":
    main()

